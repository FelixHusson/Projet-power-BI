Projet Analytique & MLOps â€” Contexte Complet
ğŸ¯ Objectif du projet
Ce projet a pour but de :

DÃ©velopper un pipeline complet de Data Science  
DÃ©ployer un modÃ¨le de Machine Learning via une API FastAPI + Docker
Construire un dashboard Power BI
Organiser le tout dans une architecture propre et industrialisable

Ce fichier sert de contexte pour les LLM et pour documenter le projet.

ğŸ—ï¸ Architecture gÃ©nÃ©rale du repository
Projet-power-BI/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # DonnÃ©es brutes
â”‚   â”œâ”€â”€ processed/          # DonnÃ©es nettoyÃ©es
â”‚   â””â”€â”€ datasets.py         # Script de gÃ©nÃ©ration/simulation de donnÃ©es
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_cleaning.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â””â”€â”€ 03_model_training.ipynb
â”‚
â”œâ”€â”€ model/
â”‚   â””â”€â”€ model.pkl           # ModÃ¨le ML entraÃ®nÃ© (pickle)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_cleaning.py    # Nettoyage des donnÃ©es
â”‚   â”œâ”€â”€ train_model.py      # EntraÃ®nement du modÃ¨le
â”‚   â””â”€â”€ api.py              # Code FastAPI
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile          # Fichier Docker (valide)
â”‚   â””â”€â”€ requirements.txt    # DÃ©pendances
â”‚
â”œâ”€â”€ powerbi/
â”‚   â””â”€â”€ dashboard.pbix      # Dashboard Power BI
â”‚
â”œâ”€â”€ README.md               # PrÃ©sentation du projet
â””â”€â”€ CONTEXT.md              # (ce fichier)

ğŸ§  Pipeline Data Science
1. Nettoyage des donnÃ©es

Suppression des valeurs manquantes  
Encodage des variables catÃ©gorielles  
Normalisation

2. Feature Engineering

Construction de nouvelles variables explicatives  
SÃ©lection de features importantes

3. EntraÃ®nement du modÃ¨le ML
ModÃ¨le typique :  

RandomForestClassifier  
XGBoost  
ou modÃ¨le de rÃ©gression

Le rÃ©sultat final est sauvegardÃ© dans :
model/model.pkl

ğŸš€ Service Web â€” API FastAPI
Le fichier dâ€™API se trouve dans :
src/api.py
Endpoints principaux
GET /               â†’ Health check
POST /predict       â†’ PrÃ©diction Ã  partir dâ€™un JSON
Exemple dâ€™appel
POST /predict
{
  "age": 43,
  "income": 35000,
  "tenure": 5
}
RÃ©ponse :
{
  "prediction": 1,
  "confidence": 0.87
}

ğŸ³ DÃ©ploiement avec Docker
Fichiers Docker
docker/
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
Contenu du Dockerfile (standard pour FastAPI)
FROM python:3.10

WORKDIR /app

COPY ../src ./src
COPY ../model ./model
COPY requirements.txt .

RUN pip install --no-cache-dir -r requirements.txt

CMD ["uvicorn", "src.api:app", "--host", "0.0.0.0", "--port", "8000"]

â–¶ï¸ Commandes Docker
Depuis le dossier :
C:\Users\felix\PycharmProjects\Projet-power-BI\docker
Build
docker build -t churn-api .
Run
docker run -p 8000:8000 churn-api
API accessible sur :
http://localhost:8000/docs

ğŸ“Š Dashboard Power BI
Le dossier powerbi/ contient :
dashboard.pbix
Contient :

KPI du modÃ¨le  
Performance (AUC, F1, confusion matrix)  
Profil client  
Analyse mÃ©tier


ğŸ§± Architecture Applicative (rÃ©sumÃ©)
Niveaux

Data Layer : data/raw, data/processed  
Machine Learning Layer : notebooks, src/train_model.py  
Model Serving Layer : FastAPI  
Containerization Layer : Docker  
BI Layer : Power BI

Flux gÃ©nÃ©ral
raw data  
â†’ cleaning  
â†’ feature engineering  
â†’ model training  
â†’ model.pkl  
â†’ FastAPI service  
â†’ Docker container  
â†’ Power BI dashboard (consomme les donnÃ©es ou outputs)

ğŸ“ Notes techniques importantes

Le fichier Dockerfile est correctement nommÃ© (pas Dockerfile.txt).  
Lors du build, il faut utiliser :

docker build -t churn-api .
depuis le dossier docker/.

Le modÃ¨le est chargÃ© dans lâ€™API via pickle.  
Le projet peut Ãªtre Ã©tendu vers un dÃ©ploiement Cloud (AWS, Azure).


ğŸ¯ UtilitÃ© de ce fichier
Ce fichier Markdown donne :

la structure complÃ¨te du projet  
les dÃ©tails du pipeline  
lâ€™architecture logicielle  
les instructions Docker  
un rÃ©sumÃ© prÃªt Ã  lâ€™emploi pour tout LLM

